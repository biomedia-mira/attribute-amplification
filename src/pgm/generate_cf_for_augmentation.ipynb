{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "sys.path.append('..')\n",
    "from train_setup import setup_directories, setup_tensorboard, setup_logging\n",
    "# From datasets import get_attr_max_min\n",
    "from vae import HVAE\n",
    "from train_pgm import preprocess, sup_epoch, eval_epoch\n",
    "from utils_pgm import plot_cf, check_nan, update_stats\n",
    "from layers import TraceStorage_ELBO\n",
    "from flow_pgm import FlowPGM\n",
    "from train_cf import DSCM\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from skimage.io import imread, imsave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(batch):\n",
    "    for k, v in batch.items():\n",
    "        if k in ['x', 'cf_x']:\n",
    "            batch[k] = (batch[k].float() - 127.5) / 127.5  # [-1,1]\n",
    "        elif k in ['age']:\n",
    "            batch[k] = batch[k].float().unsqueeze(-1)\n",
    "            batch[k] = batch[k] / 100.\n",
    "            batch[k] = batch[k] *2 -1 #[-1,1]\n",
    "        elif k in ['race']:\n",
    "            batch[k] = F.one_hot(batch[k], num_classes=3).squeeze().float()\n",
    "        elif k in ['finding']:\n",
    "            batch[k] = batch[k].unsqueeze(-1).float()\n",
    "        else:\n",
    "            try:\n",
    "                batch[k] = batch[k].float().unsqueeze(-1)\n",
    "            except:\n",
    "                batch[k] = batch[k]\n",
    "    return batch\n",
    "\n",
    "def loginfo(title, logger, stats):\n",
    "    logger.info(f'{title} | ' +\n",
    "                ' - '.join(f'{k}: {v:.4f}' for k, v in stats.items()))\n",
    "\n",
    "def inv_preprocess(pa):\n",
    "    # Undo [-1,1] parent preprocessing back to original range\n",
    "    for k, v in pa.items():\n",
    "        if k =='age':\n",
    "            pa[k] = (v + 1) / 2 * 100\n",
    "    return pa\n",
    "\n",
    "\n",
    "def vae_preprocess(args, pa):\n",
    "    pa = torch.cat([pa[k] for k in args.parents_x], dim=1)\n",
    "    pa = pa[..., None, None].repeat(\n",
    "        1, 1, *(args.input_res,)*2).float()\n",
    "    return pa\n",
    "\n",
    "\n",
    "def get_metrics(preds, targets):\n",
    "    for k, v in preds.items():\n",
    "        preds[k] = torch.stack(v).squeeze().cpu()\n",
    "        targets[k] = torch.stack(targets[k]).squeeze().cpu()\n",
    "        # print(f'{k} | preds: {preds[k].shape} - targets: {targets[k].shape}')\n",
    "    stats = {}\n",
    "    for k in preds.keys():\n",
    "        if k==\"age\":\n",
    "            preds_k = (preds[k] + 1) / 2 *100  # [-1,1] -> [0,100]\n",
    "            stats[k+'_mae'] = torch.mean(\n",
    "                torch.abs(targets[k] - preds_k)).item() \n",
    "    return stats\n",
    "\n",
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_categories = ['male', 'female']  # 0,1\n",
    "race_categories = ['White', 'Asian', 'Black']  # 0,1,2\n",
    "finding_categories = ['No disease', 'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictors\n",
    "args = Hparams()\n",
    "args.predictor_path = 'PREDICTOR_PATH'\n",
    "# args.predictor_path = '../../checkpoints/a_r_s_f/mimic_classifier_resnet34_l2_lr4_slurm/checkpoint.pt'\n",
    "predictor_checkpoint = torch.load(args.predictor_path)\n",
    "args.update(predictor_checkpoint['hparams'])\n",
    "args.use_dataset = 'mimic'\n",
    "args.csv_dir =  \"../mimic_meta\"\n",
    "args.data_dir = \"DATA_DIR\"\n",
    "args.loss_norm = \"l2\"\n",
    "predictor = FlowPGM(args)\n",
    "predictor.load_state_dict(predictor_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set PGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PGM\n",
    "args.pgm_path = '../../checkpoints/a_r_s_f/sup_pgm_mimic/checkpoint.pt'\n",
    "print(f'\\nLoading PGM checkpoint: {args.pgm_path}')\n",
    "pgm_checkpoint = torch.load(args.pgm_path)\n",
    "pgm_args = Hparams()\n",
    "pgm_args.update(pgm_checkpoint['hparams'])\n",
    "pgm = FlowPGM(pgm_args)\n",
    "pgm.load_state_dict(pgm_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.vae_path = '../../checkpoints/a_r_s_f/mimic_beta9_gelu_dgauss_1_lr3/checkpoint.pt'\n",
    "\n",
    "print(f'\\nLoading VAE checkpoint: {args.vae_path}')\n",
    "vae_checkpoint = torch.load(args.vae_path)\n",
    "vae_args = Hparams()\n",
    "vae_args.update(vae_checkpoint['hparams'])\n",
    "vae = HVAE(vae_args)\n",
    "vae.load_state_dict(vae_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DSCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Hparams()\n",
    "dscm_dir = \"DSCM_DIR\"\n",
    "which_checkpoint=\"WHICH_CHECKPOINT_TO_USE\"\n",
    "\n",
    "args.load_path = f'../../checkpoints/a_r_s_f/{dscm_dir}/{which_checkpoint}.pt'\n",
    "dscm_checkpoint = torch.load(args.load_path)\n",
    "args.update(dscm_checkpoint['hparams'])\n",
    "model = DSCM(args, pgm, predictor, vae)\n",
    "args.cf_particles =1\n",
    "model.load_state_dict(dscm_checkpoint['ema_model_state_dict'])\n",
    "model.cuda()\n",
    "elbo_fn = TraceStorage_ELBO(num_particles=1)\n",
    "\n",
    "# Set model require_grad to False\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load subgroup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subgroup\n",
    "args.bs = 1\n",
    "args.input_res =192\n",
    "from train_pgm import setup_dataloaders\n",
    "\n",
    "dataloaders = setup_dataloaders(args)\n",
    "\n",
    "print(len(dataloaders['train'].dataset), len(dataloaders['valid'].dataset), len(dataloaders['test'].dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cf(save_path_cf, cf_x):\n",
    "    _x = (cf_x.squeeze(0).squeeze(0).detach().cpu().numpy() + 1) * 127.5\n",
    "    imsave(save_path_cf, _x.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"test\"\n",
    "\n",
    "race_categories = ['White', 'Asian', 'Black']\n",
    "sex_categories = ['Male', 'Female']\n",
    "finding_categories = ['No_disease', 'Pleural_Effusion']\n",
    "\n",
    "transf = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "    ])\n",
    "\n",
    "save_dir = f\"WHERE_TO_SAVE/CF_DATA/{dscm_dir}/{which_checkpoint}/{mode}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for _race in race_categories:\n",
    "    os.makedirs(os.path.join(save_dir, f\"cf_{_race}\"), exist_ok=True)\n",
    "\n",
    "for _sex in sex_categories:\n",
    "    os.makedirs(os.path.join(save_dir, f\"cf_{_sex}\"), exist_ok=True)\n",
    "\n",
    "for _finding in finding_categories:\n",
    "    os.makedirs(os.path.join(save_dir, f\"cf_{_finding}\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(save_dir, f\"cf_Null\"), exist_ok=True)\n",
    "\n",
    "\n",
    "save_dict = {k: [] for k in ['sex', 'race','finding', 'age', 'dicom_id', \n",
    "                            'study_id', 'path_preproc',\n",
    "                            'path_cf_White', 'path_cf_Asian', 'path_cf_Black',\n",
    "                            'path_cf_Male', 'path_cf_Female', 'path_cf_Null', \n",
    "                            'path_cf_No_disease', 'path_cf_Pleural_Effusion',\n",
    "                             ]}\n",
    "                            \n",
    "for batch in tqdm(dataloaders[mode]):\n",
    "    with torch.no_grad():\n",
    "        dag_variables = list(model.pgm.variables.keys())\n",
    "        # Conditions to be saved\n",
    "        _sex = int(batch['sex'].item())\n",
    "        _finding = int(batch['finding'].item())\n",
    "        _age = int((batch['age'].item()+1)*50)\n",
    "        _race = int(batch['race'].argmax())\n",
    "        _dicom_id = batch['dicom_id'][0]\n",
    "        _study_id = batch['study_id'][0]\n",
    "\n",
    "        save_dict['sex'].append(_sex)\n",
    "        save_dict['race'].append(_race)\n",
    "        save_dict['finding'].append(_finding)\n",
    "        save_dict['age'].append(_age)\n",
    "        save_dict['path_preproc'].append(batch['path_preproc'][0])\n",
    "        save_dict['dicom_id'].append(_dicom_id)\n",
    "        save_dict['study_id'].append(_study_id)\n",
    "\n",
    "        batch = preprocess(batch)  \n",
    "        pa = {k: v for k, v in batch.items() if k in dag_variables}  \n",
    "        # Generate cfs for race\n",
    "        for cf_race in race_categories:\n",
    "            if cf_race==race_categories[_race]:\n",
    "                save_dict[f'path_cf_{race_categories[_race]}'].append('None')\n",
    "                continue\n",
    "            do = {}\n",
    "            do_k = 'race'\n",
    "            do[do_k] = F.one_hot(torch.tensor(int(race_categories.index(cf_race))), num_classes=3).repeat(len(batch[do_k]),1)\n",
    "            do = preprocess(do) # move do to gpu\n",
    "            # get counterfactual x\n",
    "            out_cf = model.forward(batch, do, elbo_fn, cf_particles=args.cf_particles)\n",
    "            cf_x = out_cf['cfs']['x']\n",
    "            cf_x = transf(cf_x) # transform cf_x from (1,1,192,192) to (1,1,224, 224)\n",
    "            save_path_cf = os.path.join(save_dir, f\"cf_{cf_race}\", f\"s{_study_id}_{_dicom_id}_cf_{cf_race}.jpg\")\n",
    "            save_cf(save_path_cf=save_path_cf, cf_x=cf_x)\n",
    "            save_dict[f'path_cf_{cf_race}'].append(save_path_cf)\n",
    "\n",
    "        # Generate null cfs\n",
    "        cf_race=race_categories[_race]\n",
    "        do = {}\n",
    "        do_k = 'race'\n",
    "        do[do_k] = F.one_hot(torch.tensor(int(race_categories.index(cf_race))), num_classes=3).repeat(len(batch[do_k]),1)\n",
    "        do = preprocess(do) # move do to gpu\n",
    "        # get counterfactual x\n",
    "        out_cf = model.forward(batch, do, elbo_fn, cf_particles=1)\n",
    "        cf_x = out_cf['cfs']['x']\n",
    "        cf_x = transf(cf_x) # transform cf_x from (1,1,192,192) to (1,1,224, 224)\n",
    "        save_path_cf = os.path.join(save_dir, f\"cf_Null\", f\"s{_study_id}_{_dicom_id}_cf_Null.jpg\")\n",
    "        save_cf(save_path_cf=save_path_cf, cf_x=cf_x)\n",
    "        save_dict[f'path_cf_Null'].append(save_path_cf)\n",
    "    \n",
    "        # Generate cfs for sex\n",
    "        for cf_sex in sex_categories:\n",
    "            if cf_sex==sex_categories[_sex]:\n",
    "                save_dict[f'path_cf_{sex_categories[_sex]}'].append('None')\n",
    "                continue\n",
    "            do = {}\n",
    "            do_k = 'sex'\n",
    "            do[do_k] = torch.tensor(int(sex_categories.index(cf_sex))).repeat(len(batch[do_k]),1)\n",
    "            do = preprocess(do) # move do to gpu\n",
    "            # get counterfactual x\n",
    "            out_cf = model.forward(batch, do, elbo_fn, cf_particles=1)\n",
    "            cf_x = out_cf['cfs']['x']\n",
    "            cf_x = transf(cf_x) # transform cf_x from (1,1,192,192) to (1,1,224, 224)\n",
    "            save_path_cf = os.path.join(save_dir, f\"cf_{cf_sex}\", f\"s{_study_id}_{_dicom_id}_cf_{cf_sex}.jpg\")\n",
    "            save_cf(save_path_cf=save_path_cf, cf_x=cf_x)\n",
    "            save_dict[f'path_cf_{cf_sex}'].append(save_path_cf)\n",
    "        \n",
    "        # Generate cfs for finding\n",
    "        for cf_finding in finding_categories:\n",
    "            if cf_finding==finding_categories[_finding]:\n",
    "                save_dict[f'path_cf_{finding_categories[_finding]}'].append('None')\n",
    "                continue\n",
    "            do = {}\n",
    "            do_k = 'finding'\n",
    "            do[do_k] = torch.tensor(int(finding_categories.index(cf_finding))).repeat(len(batch[do_k]),1)\n",
    "            do = preprocess(do) # move do to gpu\n",
    "            # get counterfactual x\n",
    "            out_cf = model.forward(batch, do, elbo_fn, cf_particles=1)\n",
    "            cf_x = out_cf['cfs']['x']\n",
    "            cf_x = transf(cf_x) # transform cf_x from (1,1,192,192) to (1,1,224, 224)\n",
    "            save_path_cf = os.path.join(save_dir, f\"cf_{cf_finding}\", f\"s{_study_id}_{_dicom_id}_cf_{cf_finding}.jpg\")\n",
    "            save_cf(save_path_cf=save_path_cf, cf_x=cf_x)\n",
    "            save_dict[f'path_cf_{cf_finding}'].append(save_path_cf)\n",
    "csv_file = os.path.join(save_dir, f'{mode}_cfs.csv' )\n",
    "df = pd.DataFrame.from_dict(save_dict)\n",
    "df.to_csv(csv_file)        \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tian_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fae4a8897f69882dc1a9e0abf776bc91929dbd910983e0126dfd7e083d88c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
