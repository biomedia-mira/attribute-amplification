{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "sys.path.append('../..')\n",
    "sys.path.append('..')\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from train_setup import setup_directories, setup_tensorboard, setup_logging\n",
    "# From datasets import get_attr_max_min\n",
    "from utils import EMA, seed_all\n",
    "from vae import HVAE\n",
    "from pgm.train_pgm import preprocess, sup_epoch, eval_epoch\n",
    "from pgm.utils_pgm import plot_cf, check_nan, update_stats\n",
    "from pgm.layers import TraceStorage_ELBO\n",
    "from pgm.flow_pgm import FlowPGM\n",
    "# from _flow_pgm_legacy import FlowPGM\n",
    "from pgm.train_cf import DSCM\n",
    "from PIL import Image\n",
    "from matplotlib import colors\n",
    "from chexploration.mimic_multitask import DenseNet\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(batch):\n",
    "    for k, v in batch.items():\n",
    "        if k == 'x':\n",
    "            batch['x'] = (batch['x'].float() - 127.5) / 127.5  # [-1,1]\n",
    "        elif k in ['age']:\n",
    "            batch[k] = batch[k].float().unsqueeze(-1)\n",
    "            batch[k] = batch[k] / 100.\n",
    "            batch[k] = batch[k] *2 -1 #[-1,1]\n",
    "        elif k in ['race']:\n",
    "            batch[k] = F.one_hot(batch[k], num_classes=3).squeeze().float()\n",
    "        elif k in ['finding']:\n",
    "            batch[k] = batch[k].unsqueeze(-1).float()\n",
    "        else:\n",
    "            batch[k] = batch[k].float().unsqueeze(-1)\n",
    "    return batch\n",
    "\n",
    "def loginfo(title, logger, stats):\n",
    "    logger.info(f'{title} | ' +\n",
    "                ' - '.join(f'{k}: {v:.4f}' for k, v in stats.items()))\n",
    "\n",
    "def inv_preprocess(pa):\n",
    "    # Undo [-1,1] parent preprocessing back to original range\n",
    "    for k, v in pa.items():\n",
    "        if k =='age':\n",
    "            pa[k] = (v + 1) / 2 * 100\n",
    "    return pa\n",
    "\n",
    "\n",
    "def vae_preprocess(args, pa):\n",
    "    pa = torch.cat([pa[k] for k in args.parents_x], dim=1)\n",
    "    pa = pa[..., None, None].repeat(\n",
    "        1, 1, *(args.input_res,)*2).float()\n",
    "    return pa\n",
    "\n",
    "\n",
    "def get_metrics(preds, targets):\n",
    "    for k, v in preds.items():\n",
    "        preds[k] = torch.stack(v).squeeze().cpu()\n",
    "        targets[k] = torch.stack(targets[k]).squeeze().cpu()\n",
    "        # print(f'{k} | preds: {preds[k].shape} - targets: {targets[k].shape}')\n",
    "    stats = {}\n",
    "    for k in preds.keys():\n",
    "        if k==\"age\":\n",
    "            preds_k = (preds[k] + 1) / 2 *100  # [-1,1] -> [0,100]\n",
    "            stats[k+'_mae'] = torch.mean(\n",
    "                torch.abs(targets[k] - preds_k)).item() \n",
    "    return stats\n",
    "\n",
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 14\n",
    "attribute_names = ['sex', 'race', 'finding']\n",
    "sex_categories = ['Male', 'Female']  # 0,1\n",
    "race_categories = ['White', 'Asian', 'Black']  # 0,1,2\n",
    "finding_categories = ['No disease', 'Pleural Effusion']\n",
    "\n",
    "target_label = \"Pleural Effusion\"    \n",
    "\n",
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    logits = []\n",
    "    preds = []\n",
    "    targets = []\n",
    "    attributes = {k:[] for k in attribute_names}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(data_loader, desc='Test-loop')):\n",
    "            img, lab = batch['x'].to(device), batch['finding'].to(device)\n",
    "            img = (img+ 1) * 127.5\n",
    "            # print(f\"img.max() {img.max()}, img.min(), {img.min()}\")\n",
    "            img = img.repeat(1,3,1,1)\n",
    "            out = model(img)[0]\n",
    "            pred = torch.sigmoid(out)\n",
    "            logits.append(out)\n",
    "            preds.append(pred)\n",
    "            targets.append(lab)\n",
    "            for k in attributes.keys():\n",
    "                attributes[k].append(batch[k])\n",
    "\n",
    "        logits = torch.cat(logits, dim=0)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        targets = torch.cat(targets, dim=0)\n",
    "        for k in attributes.keys():\n",
    "            attributes[k] = torch.cat(attributes[k], dim=0).cpu().numpy()\n",
    "\n",
    "    return preds.cpu().numpy(), targets.cpu().numpy(), logits.cpu().numpy(), attributes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictors\n",
    "args = Hparams()\n",
    "args.predictor_path = 'PREDICTOR_PATH'\n",
    "predictor_checkpoint = torch.load(args.predictor_path)\n",
    "args.update(predictor_checkpoint['hparams'])\n",
    "args.use_dataset = 'mimic'\n",
    "args.csv_dir =  \"META_DATA_DIR\"\n",
    "args.data_dir = \"DATA_DIR\"\n",
    "args.loss_norm = \"l2\"\n",
    "predictor = FlowPGM(args)\n",
    "predictor.load_state_dict(predictor_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set PGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PGM\n",
    "args.pgm_path = 'PGM_PATH'\n",
    "print(f'\\nLoading PGM checkpoint: {args.pgm_path}')\n",
    "pgm_checkpoint = torch.load(args.pgm_path)\n",
    "pgm_args = Hparams()\n",
    "pgm_args.update(pgm_checkpoint['hparams'])\n",
    "pgm = FlowPGM(pgm_args)\n",
    "pgm.load_state_dict(pgm_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.vae_path = 'VAE_PATH'\n",
    "\n",
    "print(f'\\nLoading VAE checkpoint: {args.vae_path}')\n",
    "vae_checkpoint = torch.load(args.vae_path)\n",
    "vae_args = Hparams()\n",
    "vae_args.update(vae_checkpoint['hparams'])\n",
    "vae = HVAE(vae_args)\n",
    "vae.load_state_dict(vae_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DSCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Hparams()\n",
    "dscm_dir = \"mimic_dscm_new_classifier_lr_1e4_lagrange_lr_1_damping_10\"\n",
    "which_checkpoint=\"12000_checkpoint\"\n",
    "\n",
    "\n",
    "args.load_path = f'../checkpoints/a_r_s_f/{dscm_dir}/{which_checkpoint}.pt'\n",
    "_save_fig_dir = f'SAVE_DIR/{dscm_dir}/{which_checkpoint}'\n",
    "os.makedirs(_save_fig_dir, exist_ok = True)\n",
    "dscm_checkpoint = torch.load(args.load_path)\n",
    "args.update(dscm_checkpoint['hparams'])\n",
    "model = DSCM(args, pgm, predictor, vae)\n",
    "args.cf_particles =1\n",
    "# model.load_state_dict(dscm_checkpoint['ema_model_state_dict'])\n",
    "model.load_state_dict(dscm_checkpoint['model_state_dict'])\n",
    "model.cuda()\n",
    "elbo_fn = TraceStorage_ELBO(num_particles=1)\n",
    "\n",
    "print(args.input_res)\n",
    "# Set model require_grad to False\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trianed DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "densenet = DenseNet(num_classes_disease=14, num_classes_sex=2, num_classes_race=3, class_weights_race=(1.0, 1.0, 1.0))\n",
    "\n",
    "densenet_path = \"../chexploration/multi_task_ckpt/epoch=7-step=5887.ckpt\"\n",
    "densenet_checkpoint = torch.load(densenet_path)\n",
    "densenet.load_state_dict(densenet_checkpoint['state_dict'])\n",
    "densenet = densenet.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subgroup\n",
    "args.bs = 1\n",
    "from train_pgm import setup_dataloaders\n",
    "subloaders = {}\n",
    "\n",
    "# For race\n",
    "subloaders['White'] = setup_dataloaders(args, select_subgroup=True, race_choice=\"White\")['test']\n",
    "subloaders['Black'] = setup_dataloaders(args, select_subgroup=True, race_choice=\"Black\")['test']\n",
    "subloaders['Asian'] = setup_dataloaders(args, select_subgroup=True, race_choice=\"Asian\")['test']\n",
    "\n",
    "print(f\"White: {len(subloaders['White'].dataset)}, Black: {len(subloaders['Black'].dataset)}, Asian: {len(subloaders['Asian'].dataset)}\")\n",
    "\n",
    "\n",
    "# For sex\n",
    "subloaders['Male'] = setup_dataloaders(args, select_subgroup=True, sex_choice=\"Male\")['test']\n",
    "subloaders['Female'] = setup_dataloaders(args, select_subgroup=True, sex_choice=\"Female\")['test']\n",
    "print(f\"male: {len(subloaders['Male'].dataset)}, female: {len(subloaders['Female'].dataset)}\")\n",
    "\n",
    "# For finding\n",
    "subloaders['No disease'] = setup_dataloaders(args, select_subgroup=True, finding_choice='No Finding')['test']\n",
    "subloaders['Pleural Effusion'] = setup_dataloaders(args, select_subgroup=True, finding_choice='Pleural Effusion')['test']\n",
    "print(f\"No disease: {len(subloaders['No disease'].dataset)}, Pleural Effusion: {len(subloaders['Pleural Effusion'].dataset)}\")\n",
    "\n",
    "# Race/Sex/Finding categories\n",
    "race_categories = ['White', 'Asian', 'Black']\n",
    "sex_categories = ['Male', 'Female']\n",
    "finding_categories = ['No disease', 'Pleural Effusion']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = densenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_sample = 1000 // args.bs-1\n",
    "\n",
    "def get_logits_for_attribute_a_on_CFs_intervened_on_attribute_b(attribute_a, attribute_b):\n",
    "    cf_logits = {\n",
    "        'logit - Pleural Effusion':[],\n",
    "        'logit - No Disease':[],\n",
    "        'logit - Male':[],\n",
    "        'logit - Female':[],\n",
    "        'logit - White':[],\n",
    "        'logit - Black':[],\n",
    "        'logit - Asian':[], \n",
    "        attribute_a:[],\n",
    "            }\n",
    "\n",
    "    # Select categories for attribute A \n",
    "    match attribute_a:\n",
    "        case \"sex\":\n",
    "            attr_a_category = sex_categories\n",
    "        case \"finding\":\n",
    "            attr_a_category = finding_categories\n",
    "        case \"race\":\n",
    "            attr_a_category = race_categories\n",
    "\n",
    "    # Intervened on Attribute B for subgroups classified upon Attribute A.\n",
    "    for attr_a in attr_a_category:\n",
    "        with torch.no_grad():\n",
    "            dag_variables = list(model.pgm.variables.keys())\n",
    "            count=0\n",
    "            for batch in tqdm(subloaders[attr_a]):\n",
    "                if count>_N_sample:\n",
    "                    break\n",
    "                batch = preprocess(batch)  \n",
    "                pa = {k: v for k, v in batch.items() if k in dag_variables}  \n",
    "                img = batch['x']\n",
    "                img = (img+ 1) * 127.5\n",
    "                img = img.repeat(1,3,1,1)\n",
    "\n",
    "                _logits_disease, _logits_sex, _logits_race = densenet.forward(img)\n",
    "                for _i in range(len(_logits_disease)):\n",
    "                    cf_logits[attribute_a].append(attr_a)\n",
    "                    cf_logits['logit - Pleural Effusion'].append(_logits_disease[_i][10].cpu().item())\n",
    "                    cf_logits['logit - No Disease'].append(_logits_disease[_i][0].cpu().item())\n",
    "                    cf_logits['logit - Male'].append(_logits_sex[_i][0].cpu().item())\n",
    "                    cf_logits['logit - Female'].append(_logits_sex[_i][1].cpu().item())\n",
    "                    cf_logits['logit - White'].append(_logits_race[_i][0].cpu().item())\n",
    "                    cf_logits['logit - Asian'].append(_logits_race[_i][1].cpu().item())\n",
    "                    cf_logits['logit - Black'].append(_logits_race[_i][2].cpu().item())\n",
    "                count+=1\n",
    "\n",
    "    for attr_a in attr_a_category:\n",
    "        n_train = len(subloaders[attr_a].dataset)\n",
    "        train_samples = copy.deepcopy(subloaders[attr_a].dataset.samples)\n",
    "        for k in train_samples.keys():\n",
    "            if k in ['sex', 'finding', 'age', 'race']:\n",
    "                train_samples[k]=torch.from_numpy(np.array(train_samples[k]))\n",
    "        with torch.no_grad():\n",
    "            match attribute_b:\n",
    "                case 'race':\n",
    "                    cf_title = f\"{attr_a} do(race)\"\n",
    "                case 'sex':\n",
    "                    cf_title = f\"{attr_a} do(sex)\"\n",
    "                case 'finding':\n",
    "                    cf_title = f\"{attr_a} do(disease)\"\n",
    "                case 'age':\n",
    "                    cf_title = f\"{attr_a} do(age)\"\n",
    "\n",
    "            dag_variables = list(model.pgm.variables.keys())\n",
    "            count=0\n",
    "            for batch in tqdm(subloaders[attr_a]):\n",
    "                if count>_N_sample:\n",
    "                    break\n",
    "                bs = batch['x'].shape[0]\n",
    "                \n",
    "                batch = preprocess(batch)  \n",
    "                pa = {k: v for k, v in batch.items() if k in dag_variables}  \n",
    "\n",
    "                # Intervene on Attribute B\n",
    "                do = {}\n",
    "                do_k = attribute_b\n",
    "                match attribute_b:\n",
    "                    case \"sex\":\n",
    "                        do[do_k] = 1-pa[do_k] \n",
    "                    case \"finding\":\n",
    "                        do[do_k] = 1-pa[do_k] \n",
    "                    case \"race\":\n",
    "                        batch_r = copy.deepcopy(batch)[do_k]\n",
    "                        batch_r = torch.argmax(batch_r, dim=-1)\n",
    "                        race_ = torch.bernoulli(1/2*torch.ones_like(batch_r))\n",
    "                        _do_r= (batch_r+race_+1)%3\n",
    "                        _do_r = F.one_hot(_do_r.long(), num_classes=3).squeeze().float()\n",
    "                        do[do_k]=_do_r\n",
    "                    case \"age\":\n",
    "                        do[do_k] = train_samples[do_k].clone()[torch.randperm(n_train)][:bs].unsqueeze(1)\n",
    "                        do[do_k] = (do[do_k] / 100)*2 -1\n",
    "                do = preprocess(do)\n",
    "\n",
    "                # for _k in batch.keys():\n",
    "                #     print(f\"{_k}: {batch[_k].size()}\")\n",
    "                # get counterfactual x\n",
    "                out_cf = model.forward(batch, do, elbo_fn, cf_particles=args.cf_particles)\n",
    "                img = out_cf['cfs']['x']\n",
    "                img = (img+ 1) * 127.5\n",
    "                img = img.repeat(1,3,1,1)\n",
    "                _logits_disease, _logits_sex, _logits_race = densenet.forward(img)\n",
    "                for _i in range(len(_logits_disease)):\n",
    "                    cf_logits[attribute_a].append(cf_title)\n",
    "                    cf_logits['logit - Pleural Effusion'].append(_logits_disease[_i][10].cpu().item())\n",
    "                    cf_logits['logit - No Disease'].append(_logits_disease[_i][0].cpu().item())\n",
    "                    cf_logits['logit - Male'].append(_logits_sex[_i][0].cpu().item())\n",
    "                    cf_logits['logit - Female'].append(_logits_sex[_i][1].cpu().item())\n",
    "                    cf_logits['logit - White'].append(_logits_race[_i][0].cpu().item())\n",
    "                    cf_logits['logit - Asian'].append(_logits_race[_i][1].cpu().item())\n",
    "                    cf_logits['logit - Black'].append(_logits_race[_i][2].cpu().item())\n",
    "                count+=1\n",
    "    cf_logits = pd.DataFrame.from_dict(cf_logits) \n",
    "    return cf_logits \n",
    "\n",
    "def plot_logits(cf_logits, select_keys, hue_order, attribute_a, xdat, ydat):\n",
    "    # Select subgroups\n",
    "    match attribute_a:\n",
    "        case \"race\":\n",
    "            select_cf_logits = cf_logits[cf_logits.race.isin(select_keys)]\n",
    "        case \"sex\":\n",
    "            select_cf_logits = cf_logits[cf_logits.sex.isin(select_keys)]\n",
    "        case \"finding\":\n",
    "            select_cf_logits = cf_logits[cf_logits.finding.isin(select_keys)]\n",
    "    # Randomize index\n",
    "    select_cf_logits = select_cf_logits.sample(frac=1.0).reset_index(drop=True)\n",
    "    \n",
    "    alpha = 0.6\n",
    "    style = 'o'\n",
    "    markersize = 40\n",
    "    kind = 'scatter'\n",
    "\n",
    "    sns.set_theme(style=\"white\", palette=None)\n",
    "    fig = sns.jointplot(data=select_cf_logits, \n",
    "                        x=xdat, \n",
    "                        y=ydat, \n",
    "                        hue=attribute_a, \n",
    "                        hue_order=hue_order, \n",
    "                        kind=kind, \n",
    "                        marker=style, \n",
    "                        s=markersize, \n",
    "                        alpha=alpha, \n",
    "                        joint_kws=dict(rasterized=True))\n",
    "    fig.ax_joint.legend(loc='upper right')\n",
    "    # fig.set_axis_labels('Logit - No Finding', 'Logit - Pleural Effusion')\n",
    "    # xlim_logits = fig.ax_joint.get_xlim()\n",
    "    # ylim_logits = fig.ax_joint.get_ylim()\n",
    "    title = 'logits_'+'_'.join(select_keys)\n",
    "    _fig_path = os.path.join(_save_fig_dir, 'logits')\n",
    "    os.makedirs(_fig_path, exist_ok = True)\n",
    "    fig.savefig(os.path.join(_fig_path, title+'.pdf'), bbox_inches='tight', dpi=300)\n",
    "    plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = densenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_sample = 1000 // args.bs-1\n",
    "\n",
    "from sklearn import decomposition\n",
    "import pickle as pk\n",
    "\n",
    "def pca_for_embeddings(select_cf_info, pca_file=None):\n",
    "    pd.options.mode.chained_assignment = None # Remove warning information\n",
    "    \n",
    "    if not os.path.isfile(pca_file):\n",
    "        pca = decomposition.PCA(n_components=0.99, whiten=False)\n",
    "        pca_values = pca.fit_transform(select_cf_info['embeddings'].tolist())\n",
    "        pk.dump(pca, open(pca_file,\"wb\"))\n",
    "        print(f\"Save {pca_file}\")\n",
    "    else:\n",
    "        print(f\"We load {pca_file}\")\n",
    "        pca = pk.load(open(pca_file,'rb'))\n",
    "        pca_values = pca.transform(select_cf_info['embeddings'].tolist())\n",
    "    \n",
    "    select_cf_info['pca'] = pca_values.tolist()\n",
    "    select_cf_info['pca mode 1'] = pca_values[:,0]\n",
    "    select_cf_info['pca mode 2'] = pca_values[:,1]\n",
    "    select_cf_info['pca mode 3'] = pca_values[:,2]\n",
    "    select_cf_info['pca mode 4'] = pca_values[:,3]\n",
    "    select_cf_info['pca'] = select_cf_info['pca'].tolist()\n",
    "    return select_cf_info, pca\n",
    "\n",
    "def plot_pca(cf_info, select_keys, hue_order, attribute_a):\n",
    "    # Select subgroups\n",
    "    match attribute_a:\n",
    "        case \"race\":\n",
    "            select_cf_info = cf_info[cf_info.race.isin(select_keys)]\n",
    "        case \"sex\":\n",
    "            select_cf_info = cf_info[cf_info.sex.isin(select_keys)]\n",
    "        case \"finding\":\n",
    "            select_cf_info = cf_info[cf_info.finding.isin(select_keys)]\n",
    "    # Get PCA\n",
    "    select_cf_info_with_pca, pca_trained = pca_for_embeddings(select_cf_info, pca_file=f\"pca_{attribute_a}.pkl\")\n",
    "    # Randomize index\n",
    "    select_cf_info_with_pca = select_cf_info_with_pca.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "    alpha = 0.6\n",
    "    style = 'o'\n",
    "    markersize = 40\n",
    "    kind = 'scatter'\n",
    "    xdat = 'pca mode 1'\n",
    "    ydat = 'pca mode 2'\n",
    "\n",
    "    hue_type = attribute_a\n",
    "\n",
    "    sns.set_theme(style=\"white\", palette=None)\n",
    "    fig = sns.jointplot(x=xdat, y=ydat, data=select_cf_info_with_pca,\n",
    "                        hue=hue_type, \n",
    "                        hue_order=hue_order,\n",
    "                        kind=kind,\n",
    "                        marker=style, \n",
    "                        s=markersize, \n",
    "                        alpha=alpha, \n",
    "                        joint_kws=dict(rasterized=True),\n",
    "                        )\n",
    "    fig.ax_joint.legend(loc='upper right')\n",
    "    # fig.set_axis_labels('PCA mode1', 'PCA mode2')\n",
    "\n",
    "    title_12 = 'pca12_'+'_'.join(select_keys)\n",
    "    _fig_path = os.path.join(_save_fig_dir, 'pca12')\n",
    "    os.makedirs(_fig_path, exist_ok = True)\n",
    "    fig.savefig(os.path.join(_fig_path, title_12+'.pdf'), bbox_inches='tight', dpi=800)\n",
    "    fig.savefig(os.path.join(_fig_path, title_12+'.png'), bbox_inches='tight', dpi=800)\n",
    "\n",
    "    xdat = 'pca mode 3'\n",
    "    ydat = 'pca mode 4'\n",
    "    sns.set_theme(style=\"white\", palette=None)\n",
    "    fig = sns.jointplot(x=xdat, y=ydat, data=select_cf_info_with_pca, \n",
    "                        hue=hue_type,\n",
    "                        hue_order=hue_order, \n",
    "                        kind=kind, marker=style, s=markersize, alpha=alpha,\n",
    "                        )\n",
    "    fig.ax_joint.legend(loc='upper right')\n",
    "    # fig.set_axis_labels('PCA mode3', 'PCA mode4')\n",
    "    title_34 = 'pca34_'+'_'.join(select_keys)\n",
    "    _fig_path = os.path.join(_save_fig_dir, 'pca34')\n",
    "    os.makedirs(_fig_path, exist_ok = True)\n",
    "    fig.savefig(os.path.join(_fig_path, title_34+'.pdf'), bbox_inches='tight', dpi=800)\n",
    "    fig.savefig(os.path.join(_fig_path, title_34+'.png'), bbox_inches='tight', dpi=800)\n",
    "    \n",
    "\n",
    "    fontscale = 1.6\n",
    "    color_palette = 'tab10'\n",
    "    # color_palette=['tab:blue', 'tab:orange', 'tab:red']\n",
    "    # Plot PCA mode 1\n",
    "    sns.set_theme(style=\"white\", palette=color_palette, font_scale=fontscale)\n",
    "    fig, ax = plt.subplots(figsize=(10,3))\n",
    "    g = sns.kdeplot(\n",
    "        x='pca mode 1',\n",
    "        hue=hue_type,\n",
    "        fill=True, \n",
    "        hue_order=hue_order,\n",
    "        data=select_cf_info_with_pca, \n",
    "        ax=ax, \n",
    "        common_norm=False,\n",
    "        )\n",
    "    g.get_legend().set_title(None)\n",
    "    g.spines[['right', 'top']].set_visible(False)\n",
    "    title_1 = 'pca1_'+'_'.join(select_keys)\n",
    "    _fig_path = os.path.join(_save_fig_dir, 'pca1')\n",
    "    os.makedirs(_fig_path, exist_ok = True)\n",
    "    fig.savefig(os.path.join(_fig_path, title_1+'.pdf'), bbox_inches='tight', dpi=800)\n",
    "    fig.savefig(os.path.join(_fig_path, title_1+'.png'), bbox_inches='tight', dpi=800)\n",
    "    \n",
    "    # Plot PCA mode 2\n",
    "    sns.set_theme(style=\"white\", palette=color_palette, font_scale=fontscale)\n",
    "    fig, ax = plt.subplots(figsize=(10,3))\n",
    "    g = sns.kdeplot(\n",
    "        x='pca mode 2',\n",
    "        hue=hue_type,\n",
    "        fill=True, \n",
    "        hue_order=hue_order,\n",
    "        data=select_cf_info_with_pca, \n",
    "        ax=ax, \n",
    "        common_norm=False,\n",
    "        )\n",
    "    g.get_legend().set_title(None)\n",
    "    g.spines[['right', 'top']].set_visible(False)\n",
    "    title_2 = 'pca2_'+'_'.join(select_keys)\n",
    "    _fig_path = os.path.join(_save_fig_dir, 'pca2')\n",
    "    os.makedirs(_fig_path, exist_ok = True)\n",
    "    fig.savefig(os.path.join(_fig_path, title_2+'.pdf'), bbox_inches='tight', dpi=800)\n",
    "    fig.savefig(os.path.join(_fig_path, title_2+'.png'), bbox_inches='tight', dpi=800)\n",
    "    \n",
    "    # Plot PCA mode 3\n",
    "    sns.set_theme(style=\"white\", palette=color_palette, font_scale=fontscale)\n",
    "    fig, ax = plt.subplots(figsize=(10,3))\n",
    "    g = sns.kdeplot(\n",
    "        x='pca mode 3',\n",
    "        hue=hue_type,\n",
    "        fill=True, \n",
    "        hue_order=hue_order,\n",
    "        data=select_cf_info_with_pca, \n",
    "        ax=ax, \n",
    "        common_norm=False,\n",
    "        )\n",
    "    g.get_legend().set_title(None)\n",
    "    g.spines[['right', 'top']].set_visible(False)\n",
    "    title_3 = 'pca3_'+'_'.join(select_keys)\n",
    "    _fig_path = os.path.join(_save_fig_dir, 'pca3')\n",
    "    os.makedirs(_fig_path, exist_ok = True)\n",
    "    fig.savefig(os.path.join(_fig_path, title_3+'.pdf'), bbox_inches='tight', dpi=800)\n",
    "    fig.savefig(os.path.join(_fig_path, title_3+'.png'), bbox_inches='tight', dpi=800)\n",
    "\n",
    "    # Plot PCA mode 4\n",
    "    sns.set_theme(style=\"white\", palette=color_palette, font_scale=fontscale)\n",
    "    fig, ax = plt.subplots(figsize=(10,3))\n",
    "    g = sns.kdeplot(\n",
    "        x='pca mode 4',\n",
    "        hue=hue_type,\n",
    "        fill=True, \n",
    "        hue_order=hue_order,\n",
    "        data=select_cf_info_with_pca, \n",
    "        ax=ax, \n",
    "        common_norm=False,\n",
    "        )\n",
    "    g.get_legend().set_title(None)\n",
    "    g.spines[['right', 'top']].set_visible(False)\n",
    "    title_4 = 'pca4_'+'_'.join(select_keys)\n",
    "    _fig_path = os.path.join(_save_fig_dir, 'pca4')\n",
    "    os.makedirs(_fig_path, exist_ok = True)\n",
    "    fig.savefig(os.path.join(_fig_path, title_4+'.pdf'), bbox_inches='tight', dpi=800)\n",
    "    fig.savefig(os.path.join(_fig_path, title_4+'.png'), bbox_inches='tight', dpi=800)\n",
    "\n",
    "    plt.close('all')\n",
    "    return pca_trained\n",
    "\n",
    "def get_embbedings_for_attribute_a_on_CFs_intervened_on_attribute_b(attribute_a, attribute_b):\n",
    "    cf_info = {\n",
    "        'embeddings':[], \n",
    "        attribute_a:[],\n",
    "            }\n",
    "    # Select categories for attribute A \n",
    "    match attribute_a:\n",
    "        case \"sex\":\n",
    "            attr_a_category = sex_categories\n",
    "        case \"finding\":\n",
    "            attr_a_category = finding_categories\n",
    "        case \"race\":\n",
    "            attr_a_category = race_categories\n",
    "\n",
    "    # Intervened on Attribute B for subgroups classified upon Attribute A.\n",
    "    for attr_a in attr_a_category:\n",
    "        with torch.no_grad():\n",
    "            dag_variables = list(model.pgm.variables.keys())\n",
    "            count=0\n",
    "            for batch in tqdm(subloaders[attr_a]):\n",
    "                if count>_N_sample:\n",
    "                    break\n",
    "                batch = preprocess(batch)  \n",
    "                pa = {k: v for k, v in batch.items() if k in dag_variables}  \n",
    "                img = batch['x']\n",
    "                img = (img+ 1) * 127.5\n",
    "                img = img.repeat(1,3,1,1)\n",
    "                _orig_embeddings = densenet.backbone.forward(img)\n",
    "                for _i in range(len(_orig_embeddings)):\n",
    "                    cf_info[attribute_a].append(attr_a)\n",
    "                    cf_info['embeddings'].append(_orig_embeddings[_i].cpu().numpy())\n",
    "                count+=1\n",
    "\n",
    "    for attr_a in attr_a_category:\n",
    "        n_train = len(subloaders[attr_a].dataset)\n",
    "        train_samples = copy.deepcopy(subloaders[attr_a].dataset.samples)\n",
    "        for k in train_samples.keys():\n",
    "            if k in ['sex', 'finding', 'age', 'race']:\n",
    "                train_samples[k]=torch.from_numpy(np.array(train_samples[k]))\n",
    "        with torch.no_grad():\n",
    "            match attribute_b:\n",
    "                case 'race':\n",
    "                    cf_title = f\"{attr_a} do(race)\"\n",
    "                case 'sex':\n",
    "                    cf_title = f\"{attr_a} do(sex)\"\n",
    "                case 'finding':\n",
    "                    cf_title = f\"{attr_a} do(disease)\"\n",
    "                case 'age':\n",
    "                    cf_title = f\"{attr_a} do(age)\"\n",
    "\n",
    "            dag_variables = list(model.pgm.variables.keys())\n",
    "            count=0\n",
    "            for batch in tqdm(subloaders[attr_a]):\n",
    "                if count>_N_sample:\n",
    "                    break\n",
    "                bs = batch['x'].shape[0]\n",
    "                batch = preprocess(batch)  \n",
    "                pa = {k: v for k, v in batch.items() if k in dag_variables}  \n",
    "\n",
    "                # Intervene on Attribute B\n",
    "                do = {}\n",
    "                do_k = attribute_b\n",
    "                match attribute_b:\n",
    "                    case \"sex\":\n",
    "                        do[do_k] = 1-pa[do_k] \n",
    "                    case \"finding\":\n",
    "                        do[do_k] = 1-pa[do_k] \n",
    "                    case \"race\":\n",
    "                        batch_r = copy.deepcopy(batch)[do_k]\n",
    "                        batch_r = torch.argmax(batch_r, dim=-1)\n",
    "                        race_ = torch.bernoulli(1/2*torch.ones_like(batch_r))\n",
    "                        _do_r= (batch_r+race_+1)%3\n",
    "                        _do_r = F.one_hot(_do_r.long(), num_classes=3).squeeze().float()\n",
    "                        do[do_k]=_do_r\n",
    "                    case \"age\":\n",
    "                        do[do_k] = train_samples[do_k].clone()[torch.randperm(n_train)][:bs].unsqueeze(1)\n",
    "                        do[do_k] = (do[do_k] / 100)*2 -1\n",
    "                do = preprocess(do)\n",
    "                # get counterfactual x\n",
    "                out_cf = model.forward(batch, do, elbo_fn, cf_particles=args.cf_particles)\n",
    "                img = out_cf['cfs']['x']\n",
    "                img = (img+ 1) * 127.5\n",
    "                img = img.repeat(1,3,1,1)\n",
    "                _cf_embeddings = densenet.backbone.forward(img)\n",
    "                for _i in range(len(_cf_embeddings)):\n",
    "                    cf_info[attribute_a].append(cf_title)\n",
    "                    cf_info['embeddings'].append(_cf_embeddings[_i].cpu().numpy())\n",
    "                    # cf_info['sex'].append(sex_categories[int(batch['sex'][_i].item())])\n",
    "                    # cf_info['finding'].append(\"CF_\"+finding_categories[int(batch['finding'][_i].item())])\n",
    "                count+=1\n",
    "    cf_info = pd.DataFrame.from_dict(cf_info) \n",
    "    return cf_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embeddings for Race/Sex/Finding subgroups for CFs intervened on Race/Finding/Sex/Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a,\n",
    "    attribute_b\n",
    "    ):\n",
    "    # Get embeddings\n",
    "    cf_info = get_embbedings_for_attribute_a_on_CFs_intervened_on_attribute_b(\n",
    "        attribute_a = attribute_a,\n",
    "        attribute_b = attribute_b,\n",
    "        )\n",
    "\n",
    "    # PCA for original groups\n",
    "    match attribute_a:\n",
    "        case \"race\":\n",
    "            select_keys = ['White', \"Black\", \"Asian\"]\n",
    "        case \"sex\":\n",
    "            select_keys = ['Male', \"Female\"]\n",
    "        case \"finding\":\n",
    "            select_keys = ['No disease', 'Pleural Effusion']\n",
    "    \n",
    "    _ = plot_pca(\n",
    "        cf_info=cf_info,\n",
    "        select_keys=select_keys,\n",
    "        hue_order=select_keys,\n",
    "        attribute_a=attribute_a,\n",
    "        )\n",
    "    # PCA for attribute a on CFs intervened on attribute b\n",
    "    match attribute_b:\n",
    "        case \"race\":\n",
    "            _ATTRI_B = 'race'\n",
    "        case \"sex\":\n",
    "            _ATTRI_B = \"sex\"\n",
    "        case \"age\":\n",
    "            _ATTRI_B = \"age\"\n",
    "        case \"finding\":\n",
    "            _ATTRI_B = \"disease\"\n",
    "\n",
    "    match attribute_a:\n",
    "        case \"race\":\n",
    "            select_keys_groups = [\n",
    "                ['White', 'Black', 'Asian', f'White do({_ATTRI_B})'],\n",
    "                ['White', 'Black', 'Asian', f'Asian do({_ATTRI_B})'],\n",
    "                ['White', 'Black', 'Asian', f'Black do({_ATTRI_B})'],\n",
    "                ['White', 'Black', 'Asian', f'White do({_ATTRI_B})', f'Black do({_ATTRI_B})', f'Asian do({_ATTRI_B})'],\n",
    "                ]\n",
    "        case \"sex\":\n",
    "            select_keys_groups = [\n",
    "                ['Male', \"Female\", f\"Male do({_ATTRI_B})\"],\n",
    "                ['Male', \"Female\", f\"Female do({_ATTRI_B})\"],\n",
    "                ['Male', \"Female\", f\"Male do({_ATTRI_B})\", f\"Female do({_ATTRI_B})\"],\n",
    "                ]\n",
    "        case \"finding\":\n",
    "             select_keys_groups = [\n",
    "                ['Pleural Effusion', \"No disease\", f\"Pleural Effusion do({_ATTRI_B})\"],\n",
    "                ['Pleural Effusion', \"No disease\", f\"No disease do({_ATTRI_B})\"],\n",
    "                ['Pleural Effusion', \"No disease\", f\"Pleural Effusion do({_ATTRI_B})\", f\"No disease do({_ATTRI_B})\"],\n",
    "                ]\n",
    "    \n",
    "    for _select_keys in select_keys_groups:\n",
    "        _ = plot_pca(\n",
    "            cf_info=cf_info,\n",
    "            select_keys=_select_keys,\n",
    "            hue_order=_select_keys,\n",
    "            attribute_a=attribute_a,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCAs on different attributes A on CFs of different attribute B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Race subrgoups\"\"\"\n",
    "# pca for race subgroups on sex CFs\n",
    "PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a='race',\n",
    "    attribute_b='sex'\n",
    ")\n",
    "\n",
    "# pca for race subgroups on finding CFs\n",
    "PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a='race',\n",
    "    attribute_b='finding'\n",
    ")\n",
    "\n",
    "\"\"\"Sex subrgoups\"\"\"\n",
    "# pca for sex subgroups on race CFs\n",
    "PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a='sex',\n",
    "    attribute_b='race'\n",
    ")\n",
    "\n",
    "# pca for sex subgroups on finding CFs\n",
    "PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a='sex',\n",
    "    attribute_b='finding'\n",
    ")\n",
    "\n",
    "\"\"\"Finding subrgoups\"\"\"\n",
    "# pca for finding subgroups on race CFs\n",
    "PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a='finding',\n",
    "    attribute_b='race'\n",
    ")\n",
    "\n",
    "# pca for finding subgroups on sex CFs\n",
    "PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a='finding',\n",
    "    attribute_b='sex'\n",
    ")\n",
    "\n",
    "\n",
    "PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a='finding',\n",
    "    attribute_b='finding'\n",
    ")\n",
    "\n",
    "PCA_for_Attribute_A_on_CFs_intervened_on_Attribute_B(\n",
    "    attribute_a='sex',\n",
    "    attribute_b='sex'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
