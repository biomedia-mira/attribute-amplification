{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "import pyro\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "sys.path.append('..')\n",
    "from train_setup import setup_directories, setup_tensorboard, setup_logging\n",
    "from train_pgm import setup_dataloaders\n",
    "# From datasets import get_attr_max_min\n",
    "from utils import EMA, seed_all\n",
    "from vae import HVAE\n",
    "from train_pgm import preprocess, sup_epoch, eval_epoch\n",
    "from utils_pgm import plot_cf, check_nan, update_stats\n",
    "from layers import TraceStorage_ELBO\n",
    "\n",
    "# from flow_pgm import FlowPGM_full as FlowPGM\n",
    "from flow_pgm import FlowPGM\n",
    "\n",
    "from train_cf import DSCM\n",
    "# from flow_pgm import FlowPGM_without_finding as FlowPGM\n",
    "\n",
    "def norm(batch):\n",
    "    for k, v in batch.items():\n",
    "        if k == 'x':\n",
    "            batch['x'] = (batch['x'].float() - 127.5) / 127.5  # [-1,1]\n",
    "        elif k in ['age']:\n",
    "            batch[k] = batch[k].float().unsqueeze(-1)\n",
    "            batch[k] = batch[k] / 100.\n",
    "            batch[k] = batch[k] *2 -1 #[-1,1]\n",
    "        elif k in ['race']:\n",
    "            batch[k] = F.one_hot(batch[k], num_classes=3).squeeze().float()\n",
    "        elif k in ['finding']:\n",
    "            batch[k] = batch[k].unsqueeze(-1).float()\n",
    "        else:\n",
    "            batch[k] = batch[k].float().unsqueeze(-1)\n",
    "    return batch\n",
    "\n",
    "def loginfo(title, logger, stats):\n",
    "    logger.info(f'{title} | ' +\n",
    "                ' - '.join(f'{k}: {v:.4f}' for k, v in stats.items()))\n",
    "\n",
    "def inv_preprocess(pa):\n",
    "    # Undo [-1,1] parent preprocessing back to original range\n",
    "    for k, v in pa.items():\n",
    "        if k =='age':\n",
    "            pa[k] = (v + 1) / 2 * 100\n",
    "    return pa\n",
    "\n",
    "\n",
    "def vae_preprocess(args, pa):\n",
    "    pa = torch.cat([pa[k] for k in args.parents_x], dim=1)\n",
    "    pa = pa[..., None, None].repeat(\n",
    "        1, 1, *(args.input_res,)*2).cuda().float()\n",
    "    return pa\n",
    "\n",
    "\n",
    "def get_metrics(preds, targets):\n",
    "    for k, v in preds.items():\n",
    "        preds[k] = torch.stack(v).squeeze().cpu()\n",
    "        targets[k] = torch.stack(targets[k]).squeeze().cpu()\n",
    "        # print(f'{k} | preds: {preds[k].shape} - targets: {targets[k].shape}')\n",
    "    stats = {}\n",
    "    for k in preds.keys():\n",
    "        # if k == 'mri_seq' or k == 'sex':\n",
    "        #     stats[k+'_rocauc'] = roc_auc_score(\n",
    "        #         targets[k].numpy(), preds[k].numpy(), average='macro')\n",
    "        #     stats[k+'_acc'] = (targets[k] == torch.round(preds[k])\n",
    "        #                        ).sum().item() / targets[k].shape[0]\n",
    "        if k==\"age\":\n",
    "            preds_k = (preds[k] + 1) / 2 *100  # [-1,1] -> [0,100]\n",
    "            stats[k+'_mae'] = torch.mean(\n",
    "                torch.abs(targets[k] - preds_k)).item() \n",
    "    return stats\n",
    "\n",
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_PATH= 'PREDICTOR_PATH'\n",
    "PREDICTOR_FOR_EVALUATION_PATH = 'PREDICTOR_FOR_EVALUATION_PATH'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "# Load predictors\n",
    "args = Hparams()\n",
    "args.predictor_path = PREDICTOR_PATH\n",
    "\n",
    "predictor_checkpoint = torch.load(args.predictor_path )\n",
    "args.update(predictor_checkpoint['hparams'])\n",
    "predictor_for_evaluation = FlowPGM(args).cuda()\n",
    "predictor_for_evaluation.load_state_dict(predictor_checkpoint['ema_model_state_dict'])\n",
    "\n",
    "# Load predictors\n",
    "args = Hparams()\n",
    "args.predictor_path = PREDICTOR_FOR_EVALUATION_PATH\n",
    "\n",
    "predictor_checkpoint = torch.load(args.predictor_path )\n",
    "args.update(predictor_checkpoint['hparams'])\n",
    "\n",
    "args.use_dataset = 'mimic'\n",
    "args.csv_dir =  \"../mimic_meta\"\n",
    "args.data_dir = \"DATA_DIR\"\n",
    "args.loss_norm = \"l2\"\n",
    "predictor = FlowPGM(args).cuda()\n",
    "predictor.load_state_dict(predictor_checkpoint['model_state_dict'])\n",
    "\n",
    "args.bs = 20\n",
    "args.input_res= 224\n",
    "print(args.use_dataset)\n",
    "\n",
    "dataloaders = setup_dataloaders(args)\n",
    "elbo_fn = TraceStorage_ELBO(num_particles=1)\n",
    "\n",
    "test_stats = eval_epoch(\n",
    "    predictor_for_evaluation, \n",
    "    dataloaders['valid']\n",
    ")\n",
    "\n",
    "for k,v in test_stats.items():\n",
    "    print(f\"{k}: {v:.3f} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set PGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PGM\n",
    "args.pgm_path = 'PATH OF SAVED PGM'\n",
    "print(f'\\nLoading PGM checkpoint: {args.pgm_path}')\n",
    "pgm_checkpoint = torch.load(args.pgm_path)\n",
    "pgm_args = Hparams()\n",
    "pgm_args.update(pgm_checkpoint['hparams'])\n",
    "pgm = FlowPGM(pgm_args).cuda()\n",
    "pgm.load_state_dict(pgm_checkpoint['ema_model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.vae_path = 'VAE_PATH'\n",
    "\n",
    "print(f'\\nLoading VAE checkpoint: {args.vae_path}')\n",
    "vae_checkpoint = torch.load(args.vae_path)\n",
    "vae_args = Hparams()\n",
    "vae_args.update(vae_checkpoint['hparams'])\n",
    "vae = HVAE(vae_args).cuda()\n",
    "vae.load_state_dict(vae_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DSCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSCM_DIR = \"the path where DSCM is saved\"\n",
    "WHICH_CHECKPOIBT = \"which checkpoint to choose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "args = Hparams()\n",
    "\n",
    "dscm_dir = \"DSCM_DIR\"\n",
    "which_checkpoint=\"WHICH_CHECKPOIBT\"\n",
    "\n",
    "args.load_path = f'../../checkpoints/a_r_s_f/{dscm_dir}/{which_checkpoint}.pt'\n",
    "print(args.load_path)\n",
    "dscm_checkpoint = torch.load(args.load_path )\n",
    "args.update(dscm_checkpoint['hparams'])\n",
    "model = DSCM(args, pgm, predictor, vae)\n",
    "args.cf_particles =1\n",
    "model.load_state_dict(dscm_checkpoint['ema_model_state_dict'])\n",
    "model.cuda()\n",
    "\n",
    "# Set model require_grad to False\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "transf_224 = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "    ])\n",
    "\n",
    "transf_192 = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((192, 192)),\n",
    "    ])\n",
    "\n",
    "\n",
    "model.pgm.eval()\n",
    "model.predictor.eval()\n",
    "model.vae.eval()\n",
    "dag_variables = list(model.pgm.variables.keys())\n",
    "preds = {k: [] for k in dag_variables}\n",
    "targets = {k: [] for k in dag_variables}\n",
    "args.save_dir = f\"../../results/{dscm_dir}/{which_checkpoint}\"\n",
    "os.makedirs(args.save_dir , exist_ok=True)\n",
    "# loader = tqdm(enumerate(dataloaders['test']), total=len(\n",
    "#     dataloaders['test']), mininterval=0.1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_counterfactuals(model, dataloader, predictor, do_pa=None):\n",
    "    ' this can consume lots of memory if dataset is large'\n",
    "    model.pgm.eval()\n",
    "    model.predictor.eval()\n",
    "    predictor.eval()\n",
    "    model.vae.eval()\n",
    "    dag_variables = list(model.pgm.variables.keys())\n",
    "    preds = {k: [] for k in dag_variables}\n",
    "    targets = {k: [] for k in dag_variables}\n",
    "    plt_counter = 0\n",
    "    cf_particles=1\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        # if plt_counter>10:\n",
    "        #     continue\n",
    "        plt_counter+=1\n",
    "        bs = batch['x'].shape[0]\n",
    "        batch = preprocess(batch)\n",
    "        batch['x'] = transf_192(batch['x'])\n",
    "        # randomly intervene on a single parent, where pa_k ~ p(pa_k)\n",
    "        do = {}\n",
    "        do_k = copy.deepcopy(do_pa) if do_pa else random.choice(dag_variables) \n",
    "        \n",
    "        do[do_k] = train_samples[do_k].clone()[torch.randperm(n_train)][:bs]\n",
    "        do = preprocess(norm(do))\n",
    "\n",
    "        # get counterfactual pa\n",
    "        pa = {k: v for k, v in batch.items() if k != 'x'}     \n",
    "        _pa = vae_preprocess(\n",
    "            args, {k: v.clone() for k, v in pa.items()})   \n",
    "        # cf_pa = model.pgm.counterfactual(obs=pa, intervention=do, num_particles=1)       \n",
    "        \n",
    "        # get counterfactual x\n",
    "        out = model.forward(batch, do, elbo_fn, cf_particles=cf_particles)\n",
    "        cf_pa = out['cf_pa']\n",
    "\n",
    "        nans = 0\n",
    "        for k, v in out['cfs'].items():\n",
    "        # for k, v in cfs.items():\n",
    "            k_nans = torch.isnan(v).sum()\n",
    "            nans += k_nans\n",
    "            if k_nans > 0:\n",
    "                print(f'\\nFound {k_nans} nans in cf {k}.')\n",
    "        if nans > 0:\n",
    "            continue\n",
    "        \n",
    "        out['cfs']['x'] = transf_224(out['cfs']['x'])\n",
    "        predict_out = predictor.predict(**out['cfs'])\n",
    "        # predict_out = model.predictor.predict(**cfs)\n",
    "\n",
    "        for k, v in predict_out.items():\n",
    "            preds[k].extend(v)\n",
    "        \n",
    "        # interventions are the targets for prediction\n",
    "        for k in targets.keys():\n",
    "            if k in do.keys():\n",
    "                targets[k].extend(\n",
    "                    do[k]\n",
    "                )\n",
    "            else:\n",
    "                targets[k].extend(\n",
    "                    cf_pa[k]\n",
    "                )\n",
    "    for k, v in preds.items():\n",
    "        preds[k] = torch.stack(v).squeeze().cpu()\n",
    "        targets[k] = torch.stack(targets[k]).squeeze().cpu()\n",
    "        # print(f'{k} | preds: {preds[k].shape} - targets: {targets[k].shape}')\n",
    "\n",
    "    stats = {}\n",
    "    for k in dag_variables:\n",
    "        if k in ['sex', 'finding']:\n",
    "            stats[k+'_acc'] = (targets[k].squeeze(-1) == torch.round(preds[k])).sum().item() / targets[k].shape[0]\n",
    "            stats[k+'_rocauc'] = roc_auc_score(\n",
    "                targets[k].numpy(), preds[k].numpy(), average='macro')\n",
    "        elif k == 'age':\n",
    "            stats[k] = torch.mean(torch.abs(targets[k] - preds[k])).item() * 50\n",
    "        elif k == 'race':\n",
    "            num_corrects = (targets[k].argmax(-1) == preds[k].argmax(-1)).sum()\n",
    "            stats[k + \"_acc\"] = num_corrects.item() / targets[k].shape[0]\n",
    "            # preds_k = F.one_hot(torch.argmax(F.softmax(preds[k], dim=-1), dim=-1))\n",
    "            # stats[k+'_acc'] = accuracy_score(targets[k].to(torch.int32) ,preds_k.to(torch.int32))\n",
    "            # stats[k+'_rocauc'] = roc_auc_score(\n",
    "            #     targets[k].to(torch.int32) ,preds_k.to(torch.int32),multi_class=\"ovr\",average=\"macro\",\n",
    "            # )\n",
    "            stats[k + \"_rocauc\"] = roc_auc_score(\n",
    "                targets[k].numpy(),\n",
    "                preds[k].numpy(),\n",
    "                multi_class=\"ovr\",\n",
    "                average=\"macro\",)\n",
    "    return stats, preds, targets\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_random(model, dataloader, do_pa=None):\n",
    "    ' this can consume lots of memory if dataset is large'\n",
    "    model.pgm.eval()\n",
    "    model.predictor.eval()\n",
    "    model.vae.eval()\n",
    "    dag_variables = list(model.pgm.variables.keys())\n",
    "    preds = {k: [] for k in dag_variables}\n",
    "    targets = {k: [] for k in dag_variables}\n",
    "    plt_counter = 0\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        plt_counter+=1\n",
    "        bs = batch['x'].shape[0]\n",
    "        # randomly intervene on a single parent, where pa_k ~ p(pa_k)\n",
    "        do = {}\n",
    "        do_k = copy.deepcopy(do_pa) if do_pa else random.choice(dag_variables) \n",
    "        do[do_k] = train_samples[do_k].clone()[torch.randperm(n_train)][:bs]\n",
    "\n",
    "        # get counterfactual pa\n",
    "        batch = preprocess(batch)\n",
    "        do = preprocess(norm(do))\n",
    "        pa = {k: v for k, v in batch.items() if k != 'x'}        \n",
    "        cf_pa = model.pgm.counterfactual(obs=pa, intervention=do, num_particles=1)       \n",
    "        \n",
    "        # get counterfactual x\n",
    "        _cf_pa = vae_preprocess(args, {k: v.clone() for k, v in cf_pa.items()})   \n",
    "        cf_loc, _ = model.vae.sample(parents=_cf_pa, return_loc=True)\n",
    "\n",
    "        cf_x = cf_loc\n",
    "\n",
    "        cfs = {'x': cf_x.clamp(min=-1, max=1)}\n",
    "        cfs.update(cf_pa)\n",
    "\n",
    "        nans = 0\n",
    "        for k, v in cfs.items():\n",
    "            k_nans = torch.isnan(v).sum()\n",
    "            nans += k_nans\n",
    "            if k_nans > 0:\n",
    "                print(f'\\nFound {k_nans} nans in cf {k}.')\n",
    "        if nans > 0:\n",
    "            continue\n",
    "\n",
    "        out = model.predictor.predict(**cfs)\n",
    "\n",
    "        for k, v in out.items():\n",
    "            preds[k].extend(v)\n",
    "        \n",
    "        # interventions are the targets for prediction\n",
    "        for k in targets.keys():\n",
    "            if k in do.keys():\n",
    "                targets[k].extend(\n",
    "                    do[k]\n",
    "                )\n",
    "                # print(f\"do {k}: {do[k].size()}\")\n",
    "            else:\n",
    "                targets[k].extend(\n",
    "                    cf_pa[k]\n",
    "                )\n",
    "                # print(f\"cf_pa {k}: {cf_pa[k].size()}\")\n",
    "        \n",
    "        if plt_counter<2:\n",
    "            pass\n",
    "            # plot_cf_rec(batch['x'], cf_loc, pa, cf_pa, do, rec_loc)\n",
    "            # plot_cf(batch['x'], cf_x, pa, cf_pa, do)\n",
    "\n",
    "    for k, v in preds.items():\n",
    "        preds[k] = torch.stack(v).squeeze().cpu()\n",
    "        targets[k] = torch.stack(targets[k]).squeeze().cpu()\n",
    "        # print(f'{k} | preds: {preds[k].shape} - targets: {targets[k].shape}')\n",
    "\n",
    "    stats = {}\n",
    "    for k in dag_variables:\n",
    "        if k in ['sex', 'finding']:\n",
    "            stats[k+'_rocauc'] = roc_auc_score(\n",
    "                targets[k].numpy(), preds[k].numpy(), average='macro')\n",
    "            stats[k+'_acc'] = (targets[k].squeeze(-1) == torch.round(preds[k])).sum().item() / targets[k].shape[0]\n",
    "        elif k == 'age':\n",
    "            stats[k] = torch.mean(torch.abs(targets[k] - preds[k])).item() * 50\n",
    "        elif k == 'race':\n",
    "            preds_k = F.one_hot(torch.argmax(F.softmax(preds[k], dim=-1), dim=-1))\n",
    "            # print(f\"preds_k: {preds_k.size()}\")\n",
    "            stats[k+'_acc'] = accuracy_score(targets[k].to(torch.int32) ,preds_k.to(torch.int32))\n",
    "    return stats\n",
    "\n",
    "\n",
    "\n",
    "train_samples = copy.deepcopy(dataloaders['train'].dataset.samples)\n",
    "for k in train_samples.keys():\n",
    "    if k!=\"x\":\n",
    "        try:\n",
    "            train_samples[k]=torch.from_numpy(np.array(train_samples[k]))\n",
    "        except:\n",
    "            train_samples[k]=train_samples[k]\n",
    "print(f\"train_samples: {train_samples.keys()}\")\n",
    "n_train = len(dataloaders['train'].dataset)\n",
    "\n",
    "for k,v in train_samples.items():\n",
    "    print(f\"train samples {k}: {len(v)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pgm, vae, predictor\n",
    "stats_do = { \n",
    "    'race':{},\n",
    "    'sex':{}, \n",
    "    'finding':{},\n",
    "            }\n",
    "preds_do = {\n",
    "    'race':{}, \n",
    "    'sex':{}, \n",
    "    'finding':{},\n",
    "\n",
    "            }\n",
    "targets_do = {\n",
    "    'race':{}, \n",
    "    'sex':{}, \n",
    "    'finding':{},\n",
    "\n",
    "            }\n",
    "\n",
    "for do_v in stats_do.keys():\n",
    "    stats, preds, targets = eval_counterfactuals(model, dataloaders['valid'], predictor_for_evaluation, do_pa=do_v)\n",
    "    stats_do[do_v] = stats\n",
    "\n",
    "\n",
    "for do_v in stats_do.keys():\n",
    "    print(f'do_{do_v} | '+' - '.join(f'{k}: {(v-test_stats[k])*100:.1f}' for k,v in stats_do[do_v].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for do_v in stats_do.keys():\n",
    "    print(f'do_{do_v} | '+' - '.join(f'{k}: {v:.3f}' for k,v in stats_do[do_v].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
